# IntegratedGradients_ExpectedGradients
This is a simple demo of applying Integrated Gradients and Expected Gradients to quantify the contribution of digit recognition in the mnist dataset, see the paper "Integrated Gradients is Feature Attribution methods for Neural Network(Sumdararajan et al., 2017) and "Expected Gradients is an extension of IG, which samples baseline inputs from the given dataset (Erion et al.,2019).

This deposity contains an PyTorch implementation of the aforementioned demo, this code is base on https://github.com/hobinkwak/ExpectedGradients_IntegratedGradients_pytorch and https://github.com/slundberg/shap.

# Disclaimer
This depository is made available and contributed to under the license that include terms that, for the protection of the contributors, make clear that the depository is offered “as-is”, without warranty, and disclaiming liability for damages resulting from using the depository. This guide is no different. The open content license it is offered under includes such terms.

The code may include mistakes, and can’t address every situation. If there is any question, we encourage you to do your own research, discuss with your community or contact us.

All views expressed here are from the contributors, and do not represent the opinions of any entities with which the contributors have been, are now or will be affiliated.
